{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-22T22:48:01.257588Z",
     "start_time": "2024-05-22T22:48:01.254865Z"
    }
   },
   "outputs": [],
   "source": [
    "import draco as drc\n",
    "import pandas as pd\n",
    "from vega_datasets import data as vega_data\n",
    "import altair as alt\n",
    "from IPython.display import display, Markdown\n",
    "import json\n",
    "import numpy as np\n",
    "from draco.renderer import AltairRenderer\n",
    "# alt.renderers.enable(\"png\")\n",
    "import pdb\n",
    "from draco import Draco\n",
    "dr_check=Draco()\n",
    "from itertools import permutations\n",
    "\n",
    "\n",
    "# Handles serialization of common numpy datatypes\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(NpEncoder, self).default(obj)\n",
    "\n",
    "\n",
    "def md(markdown: str):\n",
    "    display(Markdown(markdown))\n",
    "\n",
    "\n",
    "def pprint(obj):\n",
    "    md(f\"```json\\n{json.dumps(obj, indent=2, cls=NpEncoder)}\\n```\")\n",
    "\n",
    "def localpprint(obj):\n",
    "        print(json.dumps(obj, indent=2, cls=NpEncoder))\n",
    "\n",
    "def recommend_charts(\n",
    "    spec: list[str], draco: drc.Draco, df: pd.DataFrame, num: int = 5, labeler=lambda i: f\"CHART {i+1}\"\n",
    ") -> dict[str, tuple[list[str], dict]]:\n",
    "    # Dictionary to store the generated recommendations, keyed by chart name\n",
    "\n",
    "    renderer = AltairRenderer()\n",
    "    chart_specs = {}\n",
    "    chart_vega_specs = {}\n",
    "    for i, model in enumerate(draco.complete_spec(spec, num)):\n",
    "        # print(i)\n",
    "        chart_name = labeler(i)\n",
    "        spec = drc.answer_set_to_dict(model.answer_set)\n",
    "        chart_specs[chart_name] = drc.dict_to_facts(spec), spec\n",
    "        # print(chart_name)\n",
    "        # print(f\"COST: {model.cost}\")\n",
    "        chart = renderer.render(spec=spec, data=df)\n",
    "        if not ( isinstance(chart, alt.FacetChart) or isinstance(chart, alt.LayerChart)):\n",
    "            chart_vega_specs[chart_name] = {'chart': chart.to_json(), 'cost': model.cost[0]}\n",
    "\n",
    "        # # Adjust column-faceted chart size\n",
    "\n",
    "        # print(chart.to_json())\n",
    "        # display(chart)\n",
    "\n",
    "    return chart_vega_specs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def rec_from_generated_spec(\n",
    "    marks: list[str],\n",
    "    fields: list[str],\n",
    "    encoding_channels: list[str],\n",
    "    draco: drc.Draco,\n",
    "    input_spec_base: list[str],\n",
    "    data: pd.DataFrame,\n",
    "    num: int = 5, config=None\n",
    ") -> dict[str, dict]:\n",
    "    if config is None:\n",
    "        num_encodings = len(fields)\n",
    "        # make different arrangement of fields elements\n",
    "        perms_fields = list(permutations(fields))\n",
    "        input_specs = []\n",
    "        id=0\n",
    "        for fields in perms_fields:\n",
    "          for mark in marks:\n",
    "            force_attributes = []\n",
    "\n",
    "            for index, item in enumerate(fields):\n",
    "                connect_root = f'entity(encoding,m0,e{index}).'\n",
    "                force_attributes.append(connect_root)\n",
    "                specify_field = f'attribute((encoding,field),e{index},{item}).'\n",
    "                force_attributes.append(specify_field)\n",
    "            id=id+1\n",
    "            spec =(\n",
    "                    (str(id) ,mark,'only-mark'),\n",
    "                    input_spec_base\n",
    "                    +\n",
    "                    [\n",
    "                        f\"attribute((mark,type),m0,{mark}).\"\n",
    "                    ]\n",
    "                    +\n",
    "\n",
    "                    force_attributes +\n",
    "\n",
    "                    [\n",
    "                        \":- {attribute((encoding,field),_,_)} =\" + str(num_encodings) + \".\",\n",
    "                        \":- {attribute((encoding,field),_,_)} < 1.\"\n",
    "                    ]\n",
    "                )\n",
    "            input_specs.append(spec)\n",
    "\n",
    "\n",
    "        recs = {}\n",
    "        for cfg, spec in input_specs:\n",
    "            labeler = lambda i: f\"CHART {i + 1} ({' | '.join(cfg)})\"\n",
    "            try:\n",
    "                new_recs = recommend_charts(spec=spec, draco=draco, df=data, num=num, labeler=labeler)\n",
    "                recs.update(new_recs)\n",
    "            except:\n",
    "                print('Altair went wrong')\n",
    "                pass\n",
    "\n",
    "    else:\n",
    "        input_specs = validate_chart(config, input_spec_base)\n",
    "\n",
    "        recs = {}\n",
    "        j=0\n",
    "        for cfg, spec in input_specs:\n",
    "            j+=1\n",
    "            labeler = lambda i: f\"CHART {i+j + 1} ({' | '.join(cfg)})\"\n",
    "            recs= recs | recommend_charts(spec=spec, draco=draco, df=data, num=num, labeler=labeler)\n",
    "\n",
    "    # sort recs by cost\n",
    "    recs = dict(sorted(recs.items(), key=lambda item: item[1]['cost']))\n",
    "    # remove the cost from the dictionary\n",
    "    for key in recs:\n",
    "        recs[key] = recs[key]['chart']\n",
    "\n",
    "    return recs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T22:52:12.903812Z",
     "start_time": "2024-05-22T22:52:12.900716Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def validate_chart(config, input_spec_base):\n",
    "    if not config:  # If config is empty, return an empty list\n",
    "        return []\n",
    "\n",
    "    con = config[0]  # Use the first configuration in the list\n",
    "    mark = con['mark']\n",
    "    encoding = con['encoding']\n",
    "    i=0\n",
    "    input_spec = []\n",
    "    # Extract fields, aggregates, and channels from the encoding dictionary\n",
    "    for channel, attr_info in encoding.items():\n",
    "        field = attr_info.get('field')\n",
    "        aggregate = attr_info.get('aggregate')\n",
    "\n",
    "        # Ensure channel is not None\n",
    "\n",
    "        if  i==0:\n",
    "            # Generate the base input specification\n",
    "            input_spec = [\n",
    "                (mark, field, channel) if field is not None else (mark, channel),\n",
    "                input_spec_base + [\n",
    "                    f\"attribute((mark,type),m{i},{mark}).\",\n",
    "                    f\"entity(encoding,m{i},e{i}).\",\n",
    "                    f\"attribute((encoding,channel),e{i},{channel}).\",\n",
    "                ]\n",
    "            ]\n",
    "\n",
    "            # Append additional attribute for field if it's not None\n",
    "            if field is not None:\n",
    "                input_spec[1].append(f\"attribute((encoding,field),e{i},{field}).\")\n",
    "\n",
    "            # Append additional attribute for aggregate if it's not None\n",
    "            if aggregate is not None:\n",
    "                input_spec[1].append(f\"attribute((encoding,aggregate),e{i},{aggregate}).\")\n",
    "            i=i+1\n",
    "\n",
    "        elif  i>0:\n",
    "\n",
    "            input_spec[1].append(f\"entity(encoding,m{i},e{i}).\")\n",
    "            input_spec[1].append(f\"attribute((encoding,channel),e{i},{channel}).\")\n",
    "            if field is not None:\n",
    "                input_spec[1].append(f\"attribute((encoding,field),e{i},{field}).\")\n",
    "            if aggregate is not None:\n",
    "                input_spec[1].append(f\"attribute((encoding,aggregate),e{i},{aggregate}).\")\n",
    "            i=i+1\n",
    "\n",
    "\n",
    "    # Append filtering rules\n",
    "    input_spec[1].extend([\n",
    "        # exclude multi-layer designs\n",
    "        \":- {entity(mark,_,_)} != 1.\"\n",
    "    ])\n",
    "\n",
    "    return [input_spec]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T22:52:13.377941Z",
     "start_time": "2024-05-22T22:52:13.375500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def start_draco(fields,datasetname='birdstrikes',config=None):\n",
    "    # Loading data to be explored\n",
    "    d = drc.Draco()\n",
    "    if datasetname == 'movies':\n",
    "        df: pd.DataFrame = vega_data.movies()\n",
    "        # df = df.drop(columns = 'Worldwide_Gross')\n",
    "    elif datasetname=='seattle':\n",
    "        df: pd.DataFrame = vega_data.seattle_weather()\n",
    "    elif datasetname=='performance':\n",
    "        df = pd.read_csv('distribution_map.csv')\n",
    "    else:\n",
    "        df: pd.DataFrame = vega_data.birdstrikes()\n",
    "        df = df.sample(n=500, random_state=1)\n",
    "    # print(df.head(10))\n",
    "    df.columns = [col.replace('__', '_').lower() for col in df.columns]\n",
    "    df.columns = [col.replace('$', 'a') for col in df.columns]\n",
    "    data_schema = drc.schema_from_dataframe(df)\n",
    "    # pprint(data_schema)\n",
    "    data_schema_facts = drc.dict_to_facts(data_schema)\n",
    "    # print(df.columns)\n",
    "    # pprint(data_schema_facts)\n",
    "\n",
    "    input_spec_base = data_schema_facts + [\n",
    "        \"entity(view,root,v0).\",\n",
    "        \"entity(mark,v0,m0).\",\n",
    "    ]\n",
    "    # initial_recommendations = recommend_charts(spec=input_spec_base, draco=d, df=df)\n",
    "\n",
    "    recommendations = rec_from_generated_spec(\n",
    "    marks=['bar', 'point', 'circle', 'line', 'tick'],\n",
    "    fields=fields,\n",
    "    # encoding_channels=[\"x\", \"y\", \"color\"],\n",
    "    # encoding_channels=[\"color\", \"shape\", \"size\"],\n",
    "    encoding_channels=[\"x\", \"y\", \"color\", \"shape\", \"size\"],\n",
    "    draco=d,\n",
    "    input_spec_base=input_spec_base,\n",
    "    data=df,\n",
    "    config=config\n",
    "    )\n",
    "    return recommendations\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T22:52:13.890556Z",
     "start_time": "2024-05-22T22:52:13.887262Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation for CHART 1 (2 | point | only-mark):\n",
      "Recommendation for CHART 2 (2 | point | only-mark):\n",
      "Recommendation for CHART 3 (2 | point | only-mark):\n",
      "Recommendation for CHART 4 (2 | point | only-mark):\n",
      "Recommendation for CHART 5 (2 | point | only-mark):\n",
      "Recommendation for CHART 1 (7 | point | only-mark):\n",
      "Recommendation for CHART 2 (7 | point | only-mark):\n",
      "Recommendation for CHART 3 (7 | point | only-mark):\n",
      "Recommendation for CHART 4 (7 | point | only-mark):\n",
      "Recommendation for CHART 5 (7 | point | only-mark):\n",
      "Recommendation for CHART 1 (5 | tick | only-mark):\n",
      "Recommendation for CHART 2 (5 | tick | only-mark):\n",
      "Recommendation for CHART 3 (5 | tick | only-mark):\n",
      "Recommendation for CHART 4 (5 | tick | only-mark):\n",
      "Recommendation for CHART 5 (5 | tick | only-mark):\n",
      "Recommendation for CHART 1 (10 | tick | only-mark):\n",
      "Recommendation for CHART 2 (10 | tick | only-mark):\n",
      "Recommendation for CHART 3 (10 | tick | only-mark):\n",
      "Recommendation for CHART 4 (10 | tick | only-mark):\n",
      "Recommendation for CHART 5 (10 | tick | only-mark):\n",
      "Recommendation for CHART 1 (4 | line | only-mark):\n",
      "Recommendation for CHART 2 (4 | line | only-mark):\n",
      "Recommendation for CHART 3 (4 | line | only-mark):\n",
      "Recommendation for CHART 4 (4 | line | only-mark):\n",
      "Recommendation for CHART 5 (4 | line | only-mark):\n",
      "Recommendation for CHART 1 (9 | line | only-mark):\n",
      "Recommendation for CHART 2 (9 | line | only-mark):\n",
      "Recommendation for CHART 3 (9 | line | only-mark):\n",
      "Recommendation for CHART 4 (9 | line | only-mark):\n",
      "Recommendation for CHART 5 (9 | line | only-mark):\n"
     ]
    }
   ],
   "source": [
    "def get_draco_recommendations(attributes,datasetname='birdstrikes',config=None):\n",
    "    ret = [f.replace('__', '_').lower() for f in attributes]\n",
    "    field_names_renamed = [f.replace('$', 'a') for f in ret]\n",
    "    recommendations=start_draco(fields=field_names_renamed,datasetname=datasetname,config=config)\n",
    "    return recommendations\n",
    "\n",
    "# Joining the data `schema` dict with the view specification dict\n",
    "if __name__ == '__main__':\n",
    "    fields_birdstrikes = ['wildlife_species', 'wildlife_size']\n",
    "    # fields_seattle=[\"weather\", \"temp_min\", \"date\"]\n",
    "    # fields_movies = [\"major_genre\", \"us_gross\", \"source\"]\n",
    "    # fields_performance = ['Fields', 'Probability']\n",
    "    # recommendations=start_draco(fields=fields_movies, datasetname='movies')\n",
    "    recommendations=start_draco(fields=fields_birdstrikes, datasetname='birdstrikes')\n",
    "    #recommendations=start_draco(fields=fields_performance, datasetname='performance')\n",
    "\n",
    "    # recommendations=start_draco(fields=fields_seattle, datasetname='seattle')\n",
    "    # print(len(recommendations))\n",
    "    # Loop through the dictionary and print recommendations\n",
    "    for chart_key, _ in recommendations.items():\n",
    "        # (_,chart)=(recommendations[chart_key])\n",
    "        chart = recommendations[chart_key]\n",
    "        print(f\"Recommendation for {chart_key}:\")\n",
    "        # print(f\"**Draco Specification of {chart_key}**\")\n",
    "        # # # localpprint(chart)\n",
    "        # print(chart)\n",
    "        # print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T22:52:55.450329Z",
     "start_time": "2024-05-22T22:52:53.443095Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "{'CHART 1 (2 | point | only-mark)': {'$schema': 'https://vega.github.io/schema/vega-lite/v5.8.0.json',\n  'config': {'view': {'continuousHeight': 300, 'continuousWidth': 300}},\n  'data': {'name': 'data-722b4bfc7f88aef30ebf554c12f5320c'},\n  'encoding': {'size': {'aggregate': 'mean',\n    'field': 'cost_total_a',\n    'scale': {'type': 'linear', 'zero': True},\n    'type': 'quantitative'},\n   'x': {'field': 'wildlife_species', 'type': 'ordinal'},\n   'y': {'field': 'wildlife_size', 'type': 'ordinal'}},\n  'mark': {'type': 'point'}}}"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_get_draco_recommendations(attributes, datasetname='birdstrikes', config=None):\n",
    "    ret = [f.replace('__', '_').lower() for f in attributes]\n",
    "    field_names_renamed = [f.replace('$', 'a') for f in ret]\n",
    "    field_names_final = [f for f in field_names_renamed if f != 'none']\n",
    "        # If not found in precomputed, generate recommendations\n",
    "    recommendations = start_draco(fields=field_names_final, datasetname=datasetname, config=config)\n",
    "    if len(recommendations) == 0:\n",
    "        print('Draco recommendations are empty, retrying with one less field')\n",
    "        recommendations = start_draco(fields=[f for f in field_names_final[:2] if f != 'none'], datasetname=datasetname,\n",
    "                                      config=config)\n",
    "\n",
    "    if len(recommendations) > 1:\n",
    "        recos= dict(list(recommendations.items())[:1])\n",
    "        reco = remove_datapart(recos)\n",
    "        return dict(list(reco.items())[:1])\n",
    "\n",
    "\n",
    "def remove_datapart(recommendations):\n",
    "    dataset_part = None\n",
    "    chart_recom = {}\n",
    "    for chart_key, chart_json in recommendations.items():\n",
    "        chart = json.loads(chart_json)\n",
    "        if 'datasets' in chart:\n",
    "            dataset_part = chart.pop('datasets')  # Remove and store the 'datasets' part\n",
    "        chart_recom[chart_key] = chart  # Add the modified chart back to the result dictionary\n",
    "\n",
    "    # Save the dataset part to a file\n",
    "    if dataset_part:\n",
    "        with open('birdstrikes_dataset_schema.json', 'w') as f:\n",
    "            json.dump(dataset_part, f)\n",
    "\n",
    "    return chart_recom\n",
    "\n",
    "\n",
    "test_get_draco_recommendations(['wildlife_species', 'wildlife_size'], datasetname='birdstrikes')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T23:48:29.125547Z",
     "start_time": "2024-05-22T23:48:27.054704Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 4) (1584224773.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[120], line 4\u001B[0;36m\u001B[0m\n\u001B[0;31m    'attribute((encoding,field),e0,wildlife_species).', 'attribute((encoding,field),e1,cost_repair).', 'attribute((encoding,field),e2,wildlife_size)\u001B[0m\n\u001B[0m                                                                                                       ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m unterminated string literal (detected at line 4)\n"
     ]
    }
   ],
   "source": [
    "attribute((field,name),7,wildlife_size)\n",
    "\n",
    "\n",
    "'attribute((encoding,field),e0,wildlife_species).', 'attribute((encoding,field),e1,cost_repair).', 'attribute((encoding,field),e2,wildlife_size)\n",
    "\n",
    "wildlife_Speciess=8\n",
    "cost_repair=11\n",
    "\n",
    "\"encoding\": {\n",
    "    \"x\": {\n",
    "      \"aggregate\": \"count\",\n",
    "      \"scale\": {\n",
    "        \"type\": \"linear\",\n",
    "        \"zero\": true\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"mark\": {\n",
    "    \"type\": \"bar\"\n",
    "  }\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T19:40:24.451135Z",
     "start_time": "2024-05-15T19:40:24.450213Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [],
   "source": [
    "from draco import dict_to_facts, answer_set_to_dict, run_clingo\n",
    "from pprint import pprint"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T22:48:05.017664Z",
     "start_time": "2024-05-15T22:48:05.000453Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "outputs": [
    {
     "data": {
      "text/plain": "['attribute(mark,root,bar).',\n 'entity(encoding,root,0).',\n 'attribute((encoding,channel),0,x).',\n 'entity(encoding,root,1).',\n 'attribute((encoding,channel),1,y).']"
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facts = dict_to_facts(\n",
    "    {\n",
    "        \"mark\": \"bar\",\n",
    "        \"encoding\": [\n",
    "            {\"channel\": \"x\"},\n",
    "            {\"channel\": \"y\"},\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "facts"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T22:49:51.749870Z",
     "start_time": "2024-05-15T22:49:51.727025Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T22:52:18.943193Z",
     "start_time": "2024-05-15T22:52:18.934059Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'specs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[288], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m d\u001B[38;5;241m.\u001B[39mcheck_spec(\u001B[43mspecs\u001B[49m)\n\u001B[1;32m      2\u001B[0m d\u001B[38;5;241m.\u001B[39mget_violations(specs)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'specs' is not defined"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T22:53:12.479238Z",
     "start_time": "2024-05-15T22:53:12.468300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
